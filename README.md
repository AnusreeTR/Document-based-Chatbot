Hi....
The chatbot built using Streamlit and Gemini Flash operates by allowing users to upload a .txt or .pdf document and and ask questions based on its content. Once a file is uploaded, the text is extracted using PyMuPDF (fitz) for PDFs or decoded directly for text files. The extracted contnet is then split into smaller chunks using LangChain's Character Text Splitter, which helps manage long documents and maintain context. When a user inputs a question, the chatbot selects a few of these chunks and constructs a prompt that includes both the context and the question. This prompt is sent to Google's Gemini 2.5 Flash model via the google.generativeai API, which generates a relevant response. The conversation is displayed in a chat like format using Streamlit's UI components, and the chat history preserved using st.session _state. The app uses .env to securely load the Gemini API key, ensuring safe access to the model. This set up mimics a simplified Retrieval-Augmented-Generation (RAG) approach.
